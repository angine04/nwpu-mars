# engine/trainer/ema.py
import torch
from copy import deepcopy

class ModelEMA:
    """EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰æ¨¡å‹æƒé‡ç®¡ç†"""
    def __init__(self, model, decay=0.9999, tau=2000):
        # ğŸ”§ å‚æ•°éªŒè¯
        if not (0.0 < decay < 1.0):
            raise ValueError(f"EMA decay must be between 0 and 1, got {decay}")
        if tau <= 0:
            raise ValueError(f"EMA tau must be positive, got {tau}")
        
        # åˆå§‹åŒ–EMAæ¨¡å‹ï¼ˆæ·±æ‹·è´å¹¶è®¾ä¸ºevalæ¨¡å¼ï¼‰
        self.ema = deepcopy(model).eval()
        
        # ğŸ”§ ç¡®ä¿EMAæ¨¡å‹åœ¨åŒä¸€è®¾å¤‡ä¸Š
        if hasattr(model, 'outputDevice'):
            device = model.outputDevice()
        else:
            # fallback: ä½¿ç”¨æ¨¡å‹å‚æ•°çš„è®¾å¤‡
            device = next(model.parameters()).device
        self.ema = self.ema.to(device)
        
        # åŠ¨æ€è¡°å‡å‡½æ•°
        self.decay_fn = lambda x: decay * (1 - torch.exp(-torch.tensor(x / tau, dtype=torch.float32)))
        self.updates = 0
        self.decay = decay
        self.tau = tau
        
        # å†»ç»“EMAæ¨¡å‹çš„æ‰€æœ‰å‚æ•°
        for param in self.ema.parameters():
            param.requires_grad_(False)
    
    def update(self, model):
        """æ›´æ–°EMAå‚æ•°"""
        # ğŸ”§ è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥
        model_device = next(model.parameters()).device
        ema_device = next(self.ema.parameters()).device
        if model_device != ema_device:
            raise RuntimeError(f"Model and EMA model on different devices: {model_device} vs {ema_device}")
        
        with torch.no_grad():
            self.updates += 1
            d = self.decay_fn(self.updates).item()  # ç¡®ä¿æ˜¯æ ‡é‡
            
            # æ›´æ–°EMAå‚æ•°
            for ema_param, model_param in zip(self.ema.parameters(), model.parameters()):
                ema_param.mul_(d).add_(model_param.detach(), alpha=1.0 - d)
    
    def copy_attr(self, model):
        """ä»åŸæ¨¡å‹å¤åˆ¶éå‚æ•°å±æ€§ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        # å¤åˆ¶ä¸€äº›é‡è¦çš„æ¨¡å‹å±æ€§
        for attr in ['stride', 'nc', 'names', 'anchors']:
            if hasattr(model, attr):
                setattr(self.ema, attr, getattr(model, attr))
    
    def clone_model_attr(self, model):
        """å…‹éš†æ¨¡å‹çš„éå‚æ•°å±æ€§"""
        for k, v in model.__dict__.items():
            if not k.startswith('_') and k not in ['training']:
                try:
                    setattr(self.ema, k, v)
                except (AttributeError, TypeError):
                    pass
    
    def __repr__(self):
        return f'ModelEMA(decay={self.decay}, tau={self.tau}, updates={self.updates})'